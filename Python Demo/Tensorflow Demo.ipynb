{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyleregenwetter\\Anaconda3\\envs\\tftest\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/Lyleregenwetter/2.s997-Demo-Materials/main/Classification/BIKED_processed.csv'\n",
    "params = pd.read_csv(url, index_col=0)\n",
    "url='https://raw.githubusercontent.com/Lyleregenwetter/2.s997-Demo-Materials/main/Classification/Bikestyle.csv'\n",
    "classes = pd.read_csv(url, index_col=0)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "params_scaled = min_max_scaler.fit_transform(params.values)\n",
    "params_scaled = pd.DataFrame(params_scaled, columns=params.columns,index=params.index.values).astype('float32')\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(classes)\n",
    "classes_num=le.transform(classes)\n",
    "\n",
    "param_train, param_val, class_train, class_val = train_test_split(params_scaled, classes_num, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dnn(x_dims, y_dims):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=x_dims))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(200))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(200))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(y_dims))\n",
    "    model.add(tf.keras.layers.Softmax())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 200)               480400    \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 19)                3819      \n",
      "_________________________________________________________________\n",
      "softmax_4 (Softmax)          (None, 19)                0         \n",
      "=================================================================\n",
      "Total params: 524,419\n",
      "Trainable params: 524,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 2.6993 - val_loss: 2.6580\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6102 - val_loss: 2.6579\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6102 - val_loss: 2.6579\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6102 - val_loss: 2.6578\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6102 - val_loss: 2.6578\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6102 - val_loss: 2.6578\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6101 - val_loss: 2.6578\n"
     ]
    }
   ],
   "source": [
    "dnnmodel = create_dnn(2401, 19)\n",
    "dnnmodel.summary()\n",
    "dnnmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "history = dnnmodel.fit(x=param_train, y=class_train, epochs=100, batch_size=100, validation_data=(param_val, class_val), callbacks=[callback] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dnn(x_dims, y_dims):\n",
    "#     model=tf.keras.Sequential()\n",
    "#     model.add(tf.keras.layers.InputLayer(input_shape=x_dims))\n",
    "    \n",
    "#     model.add(tf.keras.layers.Dense(200))\n",
    "#     model.add(tf.keras.layers.ReLU())\n",
    "    \n",
    "#     model.add(tf.keras.layers.Dense(200))\n",
    "#     model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "#     model.add(tf.keras.layers.Dense(y_dims))\n",
    "#     model.add(tf.keras.layers.Softmax())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 200)               480400    \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 19)                3819      \n",
      "_________________________________________________________________\n",
      "softmax_3 (Softmax)          (None, 19)                0         \n",
      "=================================================================\n",
      "Total params: 524,419\n",
      "Trainable params: 524,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 2.7061 - accuracy: 0.3904 - val_loss: 2.6061 - val_accuracy: 0.4252\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6233 - accuracy: 0.4079 - val_loss: 2.6059 - val_accuracy: 0.4252\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6232 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 30/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 34/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 52/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 62/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 63/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 65/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 70/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 89/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 92/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 94/1000\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 95/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 103/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 115/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 116/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 122/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 125/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 129/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 131/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 132/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 134/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 135/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 136/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 138/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 139/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 141/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n",
      "Epoch 142/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.6231 - accuracy: 0.4079 - val_loss: 2.6058 - val_accuracy: 0.4252\n"
     ]
    }
   ],
   "source": [
    "# dnnmodel=create_dnn(2401, 19)\n",
    "# dnnmodel.summary()\n",
    "# dnnmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),)\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)\n",
    "# history = dnnmodel.fit(x=param_train, y=class_train, epochs=100, batch_size=100, validation_data=(param_val, class_val), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [2.699291229248047, 2.610243558883667, 2.61018705368042, 2.610170364379883, 2.610159158706665, 2.6101512908935547, 2.610145330429077, 2.610140323638916, 2.6101341247558594, 2.61012864112854, 2.6101267337799072, 2.6101248264312744, 2.6101245880126953, 2.610124349594116, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610124111175537, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379, 2.610123634338379], 'val_loss': [2.658024311065674, 2.657876968383789, 2.657860517501831, 2.6578493118286133, 2.6578407287597656, 2.6578357219696045, 2.6578316688537598, 2.6578264236450195, 2.6578214168548584, 2.65781831741333, 2.6578176021575928, 2.6578168869018555, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657815933227539, 2.657815933227539, 2.657816171646118, 2.657816171646118, 2.657815933227539, 2.657816171646118, 2.657816171646118, 2.657815933227539, 2.657815933227539, 2.65781569480896, 2.657815933227539, 2.65781569480896, 2.65781569480896, 2.657815456390381, 2.657815456390381, 2.657815456390381, 2.657815456390381, 2.65781569480896, 2.65781569480896, 2.65781569480896, 2.65781569480896, 2.657815933227539, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118, 2.657816171646118]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
