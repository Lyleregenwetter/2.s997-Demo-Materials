{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv(\"./BIKED_processed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x.values)\n",
    "x_scaled = pd.DataFrame(x_scaled, columns=x.columns,index=x.index.values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"images.npy\", 'rb') as f:\n",
    "    images = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_train, param_val, image_train, image_val = train_test_split(x_scaled, images, test_size=0.2, random_state=42)\n",
    "image_train=tf.cast(tf.expand_dims(image_train, -1), tf.float32)\n",
    "image_val=tf.cast(tf.expand_dims(image_val, -1), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_sigmoid_cross_entropy_loss_with_logits(x_true, x_recons_logits):\n",
    "    raw_cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=x_true, logits=x_recons_logits)\n",
    "    if len(np.shape(x_true))==4:\n",
    "        neg_log_likelihood = tf.math.reduce_sum(raw_cross_entropy, axis=[1, 2, 3])\n",
    "    else:\n",
    "        neg_log_likelihood = tf.math.reduce_sum(raw_cross_entropy, axis=[1])\n",
    "    return tf.math.reduce_mean(neg_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imVAE:\n",
    "    def __init__(self, imdims, latent_dim, kl_weight, learning_rate):\n",
    "        self.dim_x = imdims\n",
    "        self.latent_dim = latent_dim\n",
    "        self.kl_weight = kl_weight\n",
    "        self.learning_rate = learning_rate\n",
    "    def encoder(self):\n",
    "        # define prior distribution for the code, which is an isotropic Gaussian\n",
    "        prior = tfp.distributions.Independent(tfp.distributions.Normal(loc=tf.zeros(self.latent_dim), scale=1.), \n",
    "                                reinterpreted_batch_ndims=1)\n",
    "        \n",
    "        model = tf.keras.Sequential(name='encoder')\n",
    "        model.add(tf.keras.layers.InputLayer(input_shape=self.dim_x))\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2),name=\"e1\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "        model.add(tf.keras.layers.Dropout(0.1))\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(5, 5),name=\"e2\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "        model.add(tf.keras.layers.Dropout(0.1))\n",
    "        \n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(tfp.layers.IndependentNormal.params_size(self.latent_dim), name=\"e3\"))\n",
    "        \n",
    "        model.add(tfp.layers.IndependentNormal(self.latent_dim, convert_to_tensor_fn=tfp.distributions.Distribution.sample, activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior, weight=self.kl_weight), name=\"e4\"))\n",
    "        return model\n",
    "    \n",
    "    def decoder(self):\n",
    "        model = tf.keras.Sequential(name='decoder')\n",
    "        model.add(tf.keras.layers.InputLayer(input_shape=(self.latent_dim,)))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(30*65*32, name=\"layer1\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "        \n",
    "        model.add(tf.keras.layers.Dropout(0.1))\n",
    "        model.add(tf.keras.layers.Reshape(target_shape=(30, 65, 32)))\n",
    "        model.add(tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same',name=\"d1\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "        model.add(tf.keras.layers.Dropout(0.1))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same',name=\"d2\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "        model.add(tf.keras.layers.Dropout(0.1))\n",
    "\n",
    "#         model.append(layers.UpSampling2D((2,2)))\n",
    "#         model.append(layers.Conv2D(filters=96, kernel_size=3, strides=(1,1),name=\"d1\"))\n",
    "#         model.append(layers.BatchNormalization())\n",
    "#         model.append(layers.LeakyReLU())\n",
    "\n",
    "#         model.append(layers.UpSampling2D((2,2)))\n",
    "#         model.append(layers.Conv2D(filters=96, kernel_size=3, strides=(1,1),name=\"d2\"))\n",
    "#         model.append(layers.BatchNormalization())\n",
    "#         model.append(layers.LeakyReLU())\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same',name=\"d3\"))\n",
    "        \n",
    "#         model.append(keras.layers.Flatten())\n",
    "#         model.append(tfp.layers.IndependentBernoulli(self.dim_x, name='x_layer'))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def build_vae_keras_model(self):\n",
    "        x_input = tf.keras.Input(shape=self.dim_x)\n",
    "        encoder = self.encoder()\n",
    "        decoder = self.decoder()\n",
    "#         encoder.summary()\n",
    "#         decoder.summary()\n",
    "        z = encoder(x_input)\n",
    "        output=decoder(z)\n",
    "\n",
    "        negative_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "        \n",
    "        # compile VAE model\n",
    "        model = tf.keras.Model(inputs=x_input, outputs=output)\n",
    "        model.compile(loss=custom_sigmoid_cross_entropy_loss_with_logits, optimizer=tf.keras.optimizers.Adam(self.learning_rate))\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "113/113 [==============================] - 10s 62ms/step - loss: 16505.8027 - val_loss: 18020.3984\n",
      "Epoch 2/200\n",
      "113/113 [==============================] - 6s 57ms/step - loss: 9341.1250 - val_loss: 13493.4531\n",
      "Epoch 3/200\n",
      "113/113 [==============================] - 6s 57ms/step - loss: 7969.5933 - val_loss: 10728.4365\n",
      "Epoch 4/200\n",
      " 52/113 [============>.................] - ETA: 3s - loss: 7507.5737"
     ]
    }
   ],
   "source": [
    "dim_x=len(param_train.columns)\n",
    "dim_y=np.shape(image_train[1])\n",
    "imageVAE=imVAE(dim_y, 32, 1, 1e-4).build_vae_keras_model()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "imhistory = imageVAE.fit(x=image_train, y=image_train, epochs=200, batch_size=32, validation_data=(image_val, image_val),shuffle=True, callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('axes', labelsize=22)     # fontsize of the axes title\n",
    "plt.rc('axes', titlesize=22) \n",
    "figure(figsize=(8, 5))\n",
    "plt.plot(imhistory.history['loss'],color='#173000')\n",
    "plt.plot(imhistory.history['val_loss'], color='#b73000')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=(tf.math.sigmoid(imageVAE.predict(x=image_val[:16])))\n",
    "fig = plt.figure(figsize=(25, 15))\n",
    "for i in range(16):\n",
    "    idx=param_val.index[i]\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(preds[i,:,:,:], cmap=\"gray\")\n",
    "    plt.title(\"Model \" + str(idx), fontsize=20)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_train=imageVAE.layers[1].predict(image_train)\n",
    "latent_val=imageVAE.layers[1].predict(image_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressor = MLPRegressor(hidden_layer_sizes=(200, 200), max_iter=5000)\n",
    "Regressor = LinearRegression()\n",
    "# KNN = KNeighborsRegressor(n_neighbors=5)\n",
    "Regressor.fit(param_train, latent_train)\n",
    "score= Regressor.score(param_val, latent_val)\n",
    "\n",
    "print(\"Coefficient of Determination (R2): \" + str(100*score) + \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score= Regressor.score(param_train, latent_train)\n",
    "\n",
    "print(\"Coefficient of Determination (R2): \" + str(100*score) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotcomparison(preds, actual, indices):\n",
    "    fig = plt.figure(figsize=(25, 15))\n",
    "    for i in range(16):\n",
    "        if i%2==1:\n",
    "            idx=indices[i//2]\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            plt.imshow(preds[i//2,:,:,:], cmap=\"gray\")\n",
    "            plt.title(\"Model \" + str(idx), fontsize=20)\n",
    "            plt.axis('off')\n",
    "        else:\n",
    "            idx=indices[i//2]\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            plt.imshow(actual[i//2,:,:,:], cmap=\"gray\")\n",
    "            plt.title(\"Model \" + str(idx), fontsize=20)\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=tf.sigmoid(imageVAE.layers[2].predict(Regressor.predict(param_train[:8])))\n",
    "plotcomparison(preds, image_train[:8], param_train.index[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=tf.sigmoid(imageVAE.layers[2].predict(Regressor.predict(param_val[:8])))\n",
    "plotcomparison(preds, image_val[:8], param_val.index[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=0\n",
    "preds=tf.sigmoid(imageVAE.layers[2].predict(Regressor.predict(param_val)))\n",
    "for i in range(len(param_val.index)):\n",
    "    score+=tf.image.ssim(image_val[i], preds[i], 1)\n",
    "score=score/len(param_val.index)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=pd.read_csv(\"./BIKED_processed.csv\", index_col=0)\n",
    "param_test = pd.DataFrame(x_test, columns=x_test.columns,index=x_test.index.values).astype('float32')\n",
    "\n",
    "with open(\"images.npy\", 'rb') as f:\n",
    "    images = np.load(f)\n",
    "images=tf.cast(tf.expand_dims(images, -1), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=tf.sigmoid(imageVAE.layers[2].predict(Regressor.predict(param_test[:8])))\n",
    "plotcomparison(preds, image_test[:8], param_test.index[:8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
